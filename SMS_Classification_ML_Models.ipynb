{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOCB7EHDPJIoMDSl4JQwI6F",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Amadi-99/SMS_Classification_ML_Models/blob/main/SMS_Classification_ML_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Machine Learning Classifiers**\n",
        "\n",
        "**Classifiers for multilable classification**\n",
        "\n",
        "*  LinearSVC (Support Vector Classifier)\n",
        "\n",
        "*  SGDClassifier (Stochastic Gradient Descent Classifier)\n",
        "\n",
        "*  LogisticRegression\n",
        "\n",
        "*  MultinomialNB (Multinomial Naive Bayes)\n"
      ],
      "metadata": {
        "id": "p1SQoNvrRPnn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKhweSviPRJy",
        "outputId": "52285b99-6ebb-4103-eedb-0f271f5fc5d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier:  OneVsRestClassifier\n",
            "Cross-Validation Accuracy:  41.00% (+/- 17.37%)\n",
            "Clf:  SGDClassifier\n",
            "Jaccard score/Index: 80.00%\n",
            "Confusion Matrix:\n",
            "[[ 4  0  0  0]\n",
            " [ 0 10  0  0]\n",
            " [ 1  0  0  0]\n",
            " [ 2  0  0  3]]\n",
            "Accuracy: 80.00%\n",
            "Precision: 100.00%\n",
            "Recall: 76.19%\n",
            "F1 Score: 86.49%\n",
            "----\n",
            "[('otp',)]\n",
            "----\n",
            "Classifier:  OneVsRestClassifier\n",
            "Cross-Validation Accuracy:  1.25% (+/- 2.50%)\n",
            "Clf:  LogisticRegression\n",
            "Jaccard score/Index: 15.00%\n",
            "Confusion Matrix:\n",
            "[[4 0 0 0]\n",
            " [7 3 0 0]\n",
            " [1 0 0 0]\n",
            " [5 0 0 0]]\n",
            "Accuracy: 15.00%\n",
            "Precision: 100.00%\n",
            "Recall: 14.29%\n",
            "F1 Score: 25.00%\n",
            "----\n",
            "[()]\n",
            "----\n",
            "Classifier:  OneVsRestClassifier\n",
            "Cross-Validation Accuracy:  15.75% (+/- 7.89%)\n",
            "Clf:  LinearSVC\n",
            "Jaccard score/Index: 70.00%\n",
            "Confusion Matrix:\n",
            "[[ 4  0  0  0]\n",
            " [ 0 10  0  0]\n",
            " [ 1  0  0  0]\n",
            " [ 3  0  0  2]]\n",
            "Accuracy: 70.00%\n",
            "Precision: 100.00%\n",
            "Recall: 66.67%\n",
            "F1 Score: 80.00%\n",
            "----\n",
            "[('otp',)]\n",
            "----\n",
            "Classifier:  OneVsRestClassifier\n",
            "Cross-Validation Accuracy:  11.83% (+/- 4.96%)\n",
            "Clf:  MultinomialNB\n",
            "Jaccard score/Index: 50.00%\n",
            "Confusion Matrix:\n",
            "[[4 0 0 0]\n",
            " [2 8 0 0]\n",
            " [1 0 0 0]\n",
            " [5 0 0 0]]\n",
            "Accuracy: 50.00%\n",
            "Precision: 100.00%\n",
            "Recall: 47.62%\n",
            "F1 Score: 64.52%\n",
            "----\n",
            "[('otp',)]\n",
            "----\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import ast\n",
        "import warnings\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Read the dataset from the provided URL\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/Amadi-99/smsDataSet/main/smsData.csv',sep=';', index_col=0, encoding='latin-1')\n",
        "\n",
        "# Drop rows with missing values\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Preprocess the 'Text' column\n",
        "df['Text'] = df['Text'].str.strip()  # Remove leading and trailing whitespaces\n",
        "df['Text'] = df['Text'].str.replace('[^\\w\\s]', '', regex=True).str.lower()  # Remove punctuation and convert to lowercase\n",
        "df['Text'] = df['Text'].str.split()  # Tokenize text into individual words\n",
        "\n",
        "# Define stopwords to be removed\n",
        "stopwords = set(['a', 'an', 'the', 'and', 'or', 'if', 'of', 'to', 'in', 'is', 'you', 'that', 'it', 'for', 'with', 'on', 'was', 'as', 'at', 'this', 'my', 'be', 'by', 'not', 'from', 'are', 'have', 'your', 'they', 'which', 'we', 'but', 'their', 'can', 'all', 'he', 'she', 'there', 'been', 'what', 'do', 'so', 'out', 'up', 'just', 'about', 'me', 'him', 'her', 'his', 'hers', 'something', 'more', 'some', 'how', 'has', 'would', 'could', 'should', 'did', 'were', 'its', 'than', 'been'])\n",
        "df['Text'] = df['Text'].apply(lambda words: [word for word in words if word not in stopwords])  # Remove stopwords\n",
        "df['Text'] = df['Text'].apply(lambda words: ' '.join(words))  # Join the processed words back into sentences\n",
        "\n",
        "# Convert the 'Tags' column from string representation to list\n",
        "df['Tags'] = df['Tags'].apply(lambda x: ast.literal_eval(x))\n",
        "\n",
        "# Transform the multi-label tags into binary labels\n",
        "y = df['Tags']\n",
        "multilabel = MultiLabelBinarizer()\n",
        "y = multilabel.fit_transform(y)\n",
        "\n",
        "# Apply TF-IDF vectorization on the 'Text' column\n",
        "tfidf = TfidfVectorizer(analyzer='word', max_features=10000, ngram_range=(1,3), stop_words='english')\n",
        "X = tfidf.fit_transform(df['Text'])\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Define the classifiers to be used\n",
        "classifiers = [\n",
        "    SGDClassifier(),\n",
        "    LogisticRegression(solver='lbfgs'),\n",
        "    LinearSVC(),\n",
        "    MultinomialNB()\n",
        "]\n",
        "\n",
        "# Define a Jaccard score function to evaluate the performance\n",
        "def j_score(y_true, y_pred):\n",
        "    jaccard = np.minimum(y_true, y_pred).sum(axis=1) / np.maximum(y_true, y_pred).sum(axis=1)\n",
        "    return jaccard.mean() * 100\n",
        "\n",
        "# Define a function to print the scores and confusion matrix\n",
        "def print_score(y_pred, clf):\n",
        "    print(\"Clf: \", clf.__class__.__name__)\n",
        "    jaccard_score = j_score(y_test, y_pred)\n",
        "\n",
        "    # Print the Jaccard score as a percentage\n",
        "    print('Jaccard score/Index: {:.2f}%'.format(jaccard_score))\n",
        "\n",
        "\n",
        "    # Compute the confusion matrix\n",
        "    conf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
        "\n",
        "    # Print the confusion matrix\n",
        "    print(\"Confusion Matrix:\")\n",
        "    print(conf_matrix)\n",
        "\n",
        "    # Calculate accuracy, precision, recall, and F1 score\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='micro')\n",
        "    recall = recall_score(y_test, y_pred, average='micro')\n",
        "    f1 = f1_score(y_test, y_pred, average='micro')\n",
        "\n",
        "    # Print the performance metrics\n",
        "    print(\"Accuracy: {:.2f}%\".format(accuracy * 100))\n",
        "    print(\"Precision: {:.2f}%\".format(precision * 100))\n",
        "    print(\"Recall: {:.2f}%\".format(recall * 100))\n",
        "    print(\"F1 Score: {:.2f}%\".format(f1 * 100))\n",
        "    print('----')\n",
        "\n",
        "# Perform cross-validation and evaluate each model\n",
        "for classifier in classifiers:\n",
        "    clf = OneVsRestClassifier(classifier)\n",
        "    scores = cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy')\n",
        "    print(\"Classifier: \", clf.__class__.__name__)\n",
        "    print(\"Cross-Validation Accuracy:  %.2f%% (+/- %.2f%%)\" % (scores.mean() * 100, scores.std() * 100))\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    # Evaluate the model on the test set\n",
        "    y_pred = clf.predict(X_test)\n",
        "    print_score(y_pred, classifier)\n",
        "\n",
        "    # Example input for prediction\n",
        "    x = ['<#> Shadowfax Id is 152870765 6gW4yAjEoWG']\n",
        "\n",
        "    # Transform the input using the same TF-IDF vectorizer\n",
        "    xt = tfidf.transform(x)\n",
        "\n",
        "    # Make predictions on the input text\n",
        "    predicted_labels = multilabel.inverse_transform(clf.predict(xt))\n",
        "\n",
        "    # Print the predicted labels\n",
        "    print(predicted_labels)\n",
        "    print('----')"
      ]
    }
  ]
}